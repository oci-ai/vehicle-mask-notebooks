{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect image file paths\n",
    "def original_image_paths ():\n",
    "    folder = 'images/original'\n",
    "    files = os.listdir(folder)\n",
    "    files.sort()\n",
    "    files = ['{}/{}'.format(folder, file) for file in files]\n",
    "    return files\n",
    "\n",
    "# Load the images into a numpy array\n",
    "def np_read_images(img_file_paths):\n",
    "    X_data = []\n",
    "\n",
    "    for index, file_path in enumerate(img_file_paths):\n",
    "        img = mpimg.imread(file_path) \n",
    "        X_data.append(img)\n",
    "\n",
    "#     X_data = np.array(X_data, dtype = np.float32) # Convert to numpy\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the vehicles in a grid\n",
    "vehicle_paths = original_image_paths()\n",
    "vehicle_images = np_read_images(vehicle_paths)\n",
    "\n",
    "gs = gridspec.GridSpec(3, 2)\n",
    "gs.update(wspace = 0.30, hspace = 0.30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 20))\n",
    "# Front Passenger\n",
    "plt.subplot(gs[0])\n",
    "plt.imshow(vehicle_images[0])\n",
    "plt.title('Front Passenger')\n",
    "# Rear Passenger\n",
    "plt.subplot(gs[1])\n",
    "plt.imshow(vehicle_images[1])\n",
    "plt.title('Rear Passenger')\n",
    "# Rear Center\n",
    "plt.subplot(gs[2])\n",
    "plt.imshow(vehicle_images[2])\n",
    "plt.title('Rear Center')\n",
    "# Rear Driver\n",
    "plt.subplot(gs[3])\n",
    "plt.imshow(vehicle_images[3])\n",
    "plt.title('Rear Driver')\n",
    "# Front Driver\n",
    "plt.subplot(gs[4])\n",
    "plt.imshow(vehicle_images[4])\n",
    "plt.title('Front Driver')\n",
    "# Front Driver\n",
    "plt.subplot(gs[5])\n",
    "plt.imshow(vehicle_images[5])\n",
    "plt.title('Front Center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Gradients - Sobel and Scharr, Laplacian Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front Passenger\n",
    "\n",
    "img = cv2.imread('./images/original/1C4PJLCX8KD22313106.jpeg',0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0, ksize=31)\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1, ksize=31)\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "gs.update(wspace = 0.10, hspace = 0.10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16, 16))\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "plt.subplot(gs[1])\n",
    "plt.imshow(laplacian, cmap = 'gray')\n",
    "plt.title('Laplacian')\n",
    "plt.subplot(gs[2])\n",
    "plt.imshow(sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X')\n",
    "plt.subplot(gs[3])\n",
    "plt.imshow(sobely, cmap = 'viridis')\n",
    "plt.title('Sobel Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection\n",
    "OpenCV puts all the above in single function, cv2.Canny(). We will see how to use it. First argument is our input image. Second and third arguments are our minVal and maxVal respectively. Third argument is aperture_size. It is the size of Sobel kernel used for find image gradients. By default it is 3. Last argument is L2gradient which specifies the equation for finding gradient magnitude. If it is True, it uses the equation mentioned above which is more accurate, otherwise it uses this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/original/1C4PJLCX8KD22313105.jpeg')\n",
    "edges = cv2.Canny(img, 800, 400, True)\n",
    "fig, ax = plt.subplots(figsize = (16, 16))\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Foreground Extraction using GrabCut Algorithm\n",
    "\n",
    "[GrabCut algorithm](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_grabcut/py_grabcut.html#grabcut)\n",
    "\n",
    "Now we go for grabcut algorithm with OpenCV. OpenCV has the function, cv2.grabCut() for this. We will see its arguments first:\n",
    "\n",
    "- *img* - Input image\n",
    "- *mask* - It is a mask image where we specify which areas are background, foreground or probable background/foreground etc. It is done by the following flags, **cv2.GC_BGD, cv2.GC_FGD, cv2.GC_PR_BGD, cv2.GC_PR_FGD**, or simply pass 0,1,2,3 to image.\n",
    "- *rect* - It is the coordinates of a rectangle which includes the foreground object in the format (x,y,w,h)\n",
    "- *bdgModel, fgdModel* - These are arrays used by the algorithm internally. You just create two np.float64 type zero arrays of size (1,65).\n",
    "- *iterCount* - Number of iterations the algorithm should run.\n",
    "- *mode* - It should be **cv2.GC_INIT_WITH_RECT** or **cv2.GC_INIT_WITH_MASK** or combined which decides whether we are drawing rectangle or final touchup strokes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/original/1C4PJLCX8KD22313106.jpeg')\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "\n",
    "rect = (450,40,800,900)\n",
    "cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "\n",
    "plt.imshow(img),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('./images/original/1C4PJLCX8KD22313105.jpeg')\n",
    "saliency = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
    "(success, saliencyMap) = saliency.computeSaliency(image)\n",
    "saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
    "plt.imshow(saliencyMap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OpenCV's static fine grained saliency detector and\n",
    "# compute the saliency map\n",
    "saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "(success, saliencyMap) = saliency.computeSaliency(image)\n",
    " \n",
    "# if we would like a *binary* map that we could process for contours,\n",
    "# compute convex hull's, extract bounding boxes, etc., we can\n",
    "# additionally threshold the saliency map\n",
    "threshMap = cv2.threshold(saliencyMap, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    " \n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "gs.update(wspace = 0.10, hspace = 0.10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16, 16))\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "plt.subplot(gs[1])\n",
    "plt.imshow(saliencyMap)\n",
    "plt.title('saliencyMap')\n",
    "plt.subplot(gs[2])\n",
    "plt.imshow(threshMap, cmap = 'gray')\n",
    "plt.title('Thresh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import data, exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original image is inverted as the object must be white.\n",
    "image = cv2.imread('./images/original/1C4PJLCX8KD22313105.jpeg')\n",
    "\n",
    "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (16, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io as skio\n",
    "url = './images/original/1C4PJLCX8KD22313105.jpeg'\n",
    "img = skio.imread(url, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of image: {}\".format(img.shape))\n",
    "print(\"dtype of image: {}\".format(img.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "sobel = filters.sobel(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(sobel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = filters.gaussian(sobel, sigma=2.0)\n",
    "plt.imshow(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# Read the images\n",
    "foreground = cv2.imread(\"./images/original/1C4PJLCX8KD22313105.jpeg\")\n",
    "background = cv2.imread(\"./images/background.png\")\n",
    "alpha = cv2.imread(\"./images/alpha/1C4PJLCX8KD22313105.png\")\n",
    " \n",
    "# Convert uint8 to float\n",
    "foreground = foreground.astype(float)\n",
    "background = background.astype(float)\n",
    " \n",
    "# Normalize the alpha mask to keep intensity between 0 and 1\n",
    "alpha = alpha.astype(float)/255\n",
    " \n",
    "# Multiply the foreground with the alpha matte\n",
    "foreground = cv2.multiply(alpha, foreground)\n",
    " \n",
    "# Multiply the background with ( 1 - alpha )\n",
    "background = cv2.multiply(1.0 - alpha, background)\n",
    " \n",
    "# Add the masked foreground and background.\n",
    "outImage = cv2.add(foreground, background)\n",
    " \n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.imshow(outImage/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
